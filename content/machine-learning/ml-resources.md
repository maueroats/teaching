---
title: "ML Resources"
date: 2018-09-04T11:54:57-05:00
weight: 95
draft: false
#type: slide
#theme: white
description: "Resources for machine learning that we refer to in the class."
---

There is an incredible amount of information online. I will only refer
to material that I have personally read or watched. See posts on
Hacker News or Stack Overflow for others' perspectives.

{{% notice note %}}
Download the texts you use to your computer and flash drive!
{{% /notice %}}

## Texts: Primary

* [Introduction to Statistical
  Learning](http://www-bcf.usc.edu/~gareth/ISL/), a.k.a **ISLR**: The first text for
  the course. Lots of practice applying techniques on practical
  datasets. The book shows how to do the analysis in the [R language](https://www.r-project.org/), but we will
  be working in Python and implementing the algorithms on our own
  where it is practical.

## Videos

* Andrew Ng of Stanford wrote a course in [Machine
  Learning](https://www.coursera.org/learn/machine-learning): Overview
  without lots of mathematical details. Great for watching
  individually or on days the teacher is absent. Environment: free
  [Octave](https://www.gnu.org/software/octave/) or commercial
  Matlab. If you want to experiment, use [Octave
  Online](https://octave-online.net/). Although this course seems
  light on the mathematics, reviewers with serious mathematical skills
  say that it gave them the overview to understand machine learning.

* Yaser Abu-Mostafa of CalTech's [Learning from
  Data](https://work.caltech.edu/telecourse.html). Deep into the
  mathematical theory, Professor Abu-Mostafa begins with the question
  "Is learning possible?" Serious homework questions, too.

## Texts: Supplementary

* [A Course in Machine Learning](https://ciml.info): "CiML". Good points: attempts
  rigorous mathematical presentation of the material. Some proofs can
  be understood from this text that you will not find elsewhere. Bad
  points: mathematics does not seem rigorous, terms not defined, text
  has been rearranged between versions 0.9 and 0.99 leading to the
  need to read chapters out of order. Goes really fast in some places.

* Carnegie-Mellon [Math 36-401 Modern
  Regression](http://www.stat.cmu.edu/~cshalizi/mreg/15/). 

* Carnegie-Mellon [Math 36-402 Advanced Data Analysis from an
  Elementary Point of
  View](http://www.stat.cmu.edu/~cshalizi/uADA/17/). 

* CMU Machine
  Learning
  [1](https://www.cs.cmu.edu/~ninamf/courses/601sp15/lectures.shtml)
  and [2](https://www.cs.cmu.edu/~tom/10701_sp11/).
  
## Programming

* Python Data Processing

    * [Seaborn](https://seaborn.pydata.org): A pretty visualization
      library.
    * [Matplotlib](https://matplotlib.org/): Harder to use, more control.
    * [Pandas](http://pandas.pydata.org/pandas-docs/stable/): Managing
      related data assembled together into one "data frame".
    * [NumPy](https://docs.scipy.org/doc/numpy/user/) and its big
      cousin [SciPy](https://docs.scipy.org/doc/scipy/reference/):
      numerical mathematics of all kinds.

* Tutorials

    * [Pandas Cookbook](https://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.2/cookbook/A%20quick%20tour%20of%20IPython%20Notebook.ipynb): Excellent tutorial by [Julia Evans](https://jvns.ca/), mad hacker, blogger, author.
    * [Data analysis with Python and Pandas](https://pythonprogramming.net/data-analysis-python-pandas-tutorial-introduction/): decent.

* [Kaggle](https://www.kaggle.com/) 

    Use Kaggle to test the ideas that you have learned in a realistic
    situation. I would stick with the classic data sets for a _long_
    time; they should be challenging enough. 
   
   

